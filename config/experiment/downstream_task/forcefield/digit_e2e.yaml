# @package _global_
defaults:
  - /paths: ~
  - /wandb: ~
  - /data: digit
  - /task: digit_forcefield
  - _self_

ssl_name: e2e
sensor: digit
ckpt_path: ~

task_name: t1_forcefield
ssl_model_size: base
train_data_budget: 1.0
val_data_budget: 1.0
experiment_name: ${sensor}_${task_name}_${ssl_name}_vit${ssl_model_size}_bg_e2e
seed: 42

data_out_format: 'concat_ch_img'
num_frames: 2
frame_stride: 5

hydra:
  job:
    id: ${now:%Y.%m.%d}_${now:%H-%M}
  run:
    dir: ${paths.log_dir}/${hydra.job.id}_${experiment_name}
    
wandb:
  project: ${task_name}_${sensor}
  group: ~
  tags: ["${ssl_name}"]

trainer:
  max_epochs: 31
  validation_frequency: 2
  sanity_validate: false
  save_checkpoint_dir: ${paths.output_dir}/checkpoints
  checkpoint_interval_type: 'log'
  max_task_checkpoints: 10
  save_probe_weights_only: True
  limit_train_batches: 500
  limit_val_batches: 150

data:
  train_data_budget: ${train_data_budget}
  val_data_budget: ${val_data_budget}
  train_dataloader:
    batch_size: 15
    num_workers: 2
  val_dataloader:
    batch_size: 15
    num_workers: 2


test:
  data:
    dataset_name: ["005_tomato_soup_can/dataset_4"]
    batch_size: 1
  tester:
    _partial_: True
    _target_: tactile_ssl.test.TestForceField
  demo:
    _partial_: True
    _target_: tactile_ssl.test.DemoForceField
  path_outputs: ~


task:
  _target_: tactile_ssl.downstream_task.ForceFieldModule
  checkpoint_task: ~

  model_encoder:
    _target_: tactile_ssl.model.vit_${ssl_model_size}
    img_size: [224, 224]
    in_chans: 6
    pos_embed_fn: sinusoidal
    num_register_tokens: 1

  model_task:
    _target_: tactile_ssl.downstream_task.ForceFieldDecoder
    embed_dim: ${ssl_model_size}

  ssl_config:
    img_sz: [224, 224]
    pose_estimator:
      num_encoder_layers: 18
    loss:
      with_mask_supervision: false
      with_sl_supervision: false
      with_ssim: true
      disparity_smoothness: 1e-3
      min_depth: 0.1
      max_depth: 100.0

  checkpoint_encoder: ~
  train_encoder: true
  encoder_type: ${ssl_name}

  optim_cfg:
    _partial_: True 
    _target_: torch.optim.Adam
    lr: 0.0001

  scheduler_cfg: ~
